{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **FitBot Conversational Model** \n",
    "---\n",
    "The conversational bot that helps you with your diet and anything else you need to achieve a more balanced and aware life\n",
    "\n",
    "## Architecture\n",
    "---\n",
    "<center><img src = \"https://github.com/Niccoborg22/virtual-nutritionist-bot/raw/master/image.png\"></center>\n",
    "\n",
    "## File structure\n",
    "---\n",
    "The file is structured following this structure: \n",
    "1. Imports \n",
    "2. NLP Conversational Model \n",
    "    - Authentication\n",
    "    - Session creation\n",
    "3. Large Language Model \n",
    "    - Authentication\n",
    "    - Environment set up\n",
    "4. Computer Vision Model \n",
    "    - Authentication\n",
    "    - Environment set up\n",
    "5. Function development \n",
    "6. Web Application\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "---\n",
    "Import of all the libraries needed in the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP Conversational Model\n",
    "from google.cloud import dialogflow\n",
    "import uuid\n",
    "from google.oauth2 import service_account\n",
    "import random\n",
    "import time\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large Language Model\n",
    "from google.oauth2 import service_account\n",
    "from vertexai.preview.language_models import TextGenerationModel\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.20  Python-3.10.9 torch-2.0.1+cpu CPU\n",
      "Setup complete  (8 CPUs, 7.8 GB RAM, 313.5/475.7 GB disk)\n"
     ]
    }
   ],
   "source": [
    "# Computer Vision Model\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from roboflow import Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "# Web Application\n",
    "import gradio as gr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Conversational Model \n",
    "--- \n",
    "The NLP Conversational Model has been developed using the following technologies: \n",
    "- Google Dialogflow \n",
    "- Python\n",
    "\n",
    "### Authentication\n",
    "The first step is authenticate the computer in the Google Cloud platform. Following the best practices, a service account with the least priviledge principle has been created for it and it has been used to connect to the cloud. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_account_key = os.getenv('service_account_key')\n",
    "credentials = service_account.Credentials.from_service_account_file(service_account_key)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session Creation\n",
    "A session represents a conversation between a Dialogflow agent and an end-user. You create a session at the beginning of a conversation and use it for each turn of the conversation. Once the conversation has ended, you discontinue using the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = uuid.uuid4().hex\n",
    "\n",
    "# Load the variables to access the databases\n",
    "project_id = os.getenv('project_id')\n",
    "language_code = 'en'\n",
    "\n",
    "# Create the session with the appropriate credentials\n",
    "session_client = dialogflow.SessionsClient(credentials=credentials)\n",
    "\n",
    "session = session_client.session_path(project_id, session_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Language Model \n",
    "--- \n",
    "The Large Language Model connection has been developed using the following technologies: \n",
    "- Google Vertex AI\n",
    "- Python\n",
    "\n",
    "### Authentication\n",
    "The first step is authenticate the computer in the Google Cloud platform. Following the best practices, a service account with the least priviledge principle has been created for it and it has been used to connect to the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = os.getenv('region')\n",
    "aiplatform.init(project=project_id, location=region)\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = service_account_key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment set up\n",
    "When using vertex AI certain paramenters must be set up including most importantly the temperature and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"max_output_tokens\": 1024,  # Token limit determines the maximum amount of text output.\n",
    "    \"top_p\": 0.8,  # Tokens are selected from most probable to least until the sum of their probabilities equals the top_p value.\n",
    "    \"top_k\": 40,  # A top_k of 1 means the selected token is the most probable among all tokens.\n",
    "}\n",
    "\n",
    "model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Vision Model \n",
    "--- \n",
    "The Computer Vision Model connection has been developed using the following technologies: \n",
    "- Dialogflow\n",
    "    - YoloV8\n",
    "- Python\n",
    "\n",
    "### Authentication\n",
    "The first step is authenticate the computer in the Dialogflow platform. In order to do so an api_key is necessary. The key has been saved as an environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv('roboflow_api_key')\n",
    "rf = Roboflow(api_key=api_key)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Set Up\n",
    "In order to connect to the right model, the model and version must be defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "project = rf.workspace().project(\"food_detection-cxap6\")\n",
    "vision_model = project.version(1).model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function development\n",
    "---\n",
    "Now that all the models are initiated and ready to be used, the functions that will handle the exchange between them will be defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to request an answer to our dialogflow agent according to a text \n",
    "def dialogflow_request(text, language_code):\n",
    "    text_input = dialogflow.TextInput(text=text, language_code=language_code)\n",
    "    query_input = dialogflow.QueryInput(text=text_input)\n",
    "    response = session_client.detect_intent(\n",
    "        request={\"session\": session, \"query_input\": query_input}\n",
    "    )\n",
    "    response_message = str(response.query_result.fulfillment_messages[0].text.text[0])\n",
    "    # If statement to connect to the LLM model in specific cases\n",
    "    if \"<<<llmquestion\" in response_message:\n",
    "        llm_response = model.predict((response_message.split(\"<<<llmquestion:\")[1][:-3]), **parameters)\n",
    "        return llm_response.text\n",
    "    else:\n",
    "        return response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_recognition(imagePath):\n",
    "    try:\n",
    "        results = vision_model.predict(imagePath, confidence=40, overlap=30).json()\n",
    "        if results['predictions'] == []:\n",
    "            prediction = 'Not found'\n",
    "        else:\n",
    "            prediction = results['predictions'][0]['class']\n",
    "    except Exception as e:\n",
    "        prediction = 'Error: ' + str(e)\n",
    "        print(prediction)\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Application functions to allow the front-end to interact with the user\n",
    "def respond(message, chat_history):\n",
    "    if len(chat_history) != 0 and (chat_history[-1][-1] == \"Sure, please provide the path to an image (local or url).\" or chat_history[-1][-1] == \"No food detected. Please provide another image path.\" or chat_history[-1][-1] == \"Invalid path. Please provide another image path.\"):\n",
    "        prediction = image_recognition(''.join(message.split()).replace(\"'\", \"\"))\n",
    "        if \"No such file or directory\" in prediction:\n",
    "            chat_history.append((message, \"Invalid path. Please provide another image path.\"))\n",
    "        elif prediction == \"Not found\":\n",
    "            chat_history.append((message, \"No food detected. Please provide another image path.\"))\n",
    "        else:\n",
    "            bot_message = dialogflow_request(''.join(prediction.split()).replace(\"'\", \"\"), 'en')\n",
    "            chat_history.append((message, bot_message))\n",
    "    elif isinstance(message, str):\n",
    "        # If the message is a string, treat it as a text input\n",
    "        bot_message = dialogflow_request(message, 'en')\n",
    "        chat_history.append((message, bot_message))\n",
    "\n",
    "    else:\n",
    "        bot_message = \"Invalid input\"\n",
    "        chat_history.append((message, bot_message))\n",
    "    \n",
    "    time.sleep(1)\n",
    "    return \"\", chat_history\n",
    "\n",
    "# Function to add a file\n",
    "def add_file(history, file):\n",
    "    history.append(((file.name,), None))\n",
    "    return history\n",
    "\n",
    "# Function to add text to the chat\n",
    "def add_text(history, text):\n",
    "    history.append((text, None))\n",
    "    return history, respond(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Application \n",
    "---\n",
    "The Web Application has been developed using the following technologies: \n",
    "- Gradio\n",
    "- Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "You have unused kwarg parameters in Row, please remove them: {'scale': 0.7}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app. \n",
      "\n",
      "Also please ensure that your antivirus or firewall is not blocking the binary file located at: c:\\Users\\borga\\Desktop\\IE Computer Science\\Semester 3\\NLP Conversational Model\\Final Project\\myenv\\lib\\site-packages\\gradio\\frpc_windows_amd64_v0.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks(css=\".gradio-container {background-color: #0E2C4B}\") as demo:\n",
    "    disclaimer_agreed = gr.State(False)\n",
    "    def conditions_met(newValue):\n",
    "        disclaimer_agreed.value = newValue\n",
    "    \n",
    "    gr.Markdown(\"\"\"\n",
    "            <h1 style=\"text-align: center; color:white;\" >FitBot</h1>\n",
    "            <h4 style=\"text-align: center; color:white\">Your personal food and health assistant</h4>\n",
    "            \"\"\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=4):\n",
    "            # Create a chatbot component and a model component\n",
    "            chatbot = gr.Chatbot([], elem_id=\"chatbot\", label=\"FitBot\").style()\n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"\"\"\n",
    "            <h2 style=\"color:white\" >Disclaimer</h2>\n",
    "            <p style=\"color:white\">The following bot is not meant following any regulatory health practice. All the information that is presented to you\n",
    "            is generated from Vertex AI, the generative AI developed by Google. If you are interested in knowing more about the project and how this model\n",
    "            was built, please refer to the following <a href=\"https://github.com/Niccoborg22/virtual-nutritionist-bot\" style=\"color:white\">Github link</a></p>\n",
    "            \"\"\")\n",
    "\n",
    "    with gr.Row():\n",
    "        # Create a textbox component\n",
    "        with gr.Column(scale=8):\n",
    "            msg = gr.Textbox(\n",
    "                show_label=False,\n",
    "                placeholder=\"Enter text and press enter, or upload an image\",\n",
    "            ).style(container=False)\n",
    "        with gr.Column(scale=1, min_width=0):\n",
    "            # Create an upload button component to add images\n",
    "            btn = gr.UploadButton(\"📁\", file_types=[\"image\"])\n",
    "\n",
    "    with gr.Row(scale=0.7):\n",
    "        clear_btn = gr.Button(value=\"🗑️  Clear\")\n",
    "\n",
    "    \n",
    "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "    file_msg = btn.upload(add_file, [chatbot, btn], [chatbot], queue=False)\n",
    "    clear_btn.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "    \n",
    "\n",
    "# launch the application\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
