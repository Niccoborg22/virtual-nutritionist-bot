{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path\n",
    "1. Create the model in GCP\n",
    "    - Create the Dialogflow structure\n",
    "    - Implement the PaLM into the Dialogflow\n",
    "    - Test it out \n",
    "2. Make the backend locally\n",
    "3. Create a Front End\n",
    "4. Deploy the Front End"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Improvements\n",
    "- Add identification in the frontend and change the conversational model if the user is identified. For example in the welcome intent instead of saying the fir interaction, get it ready to do something\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "Importing all the libraries needed to run the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\borga\\Desktop\\IE Computer Science\\Semester 3\\NLP Conversational Model\\Final Project\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import dialogflow\n",
    "import uuid\n",
    "from google.oauth2 import service_account\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "import random\n",
    "import time\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent creation\n",
    "---\n",
    "**ADD IMAGES ONCE FINISHED**\n",
    "\n",
    "\n",
    "# Agent connection\n",
    "---\n",
    "In order to connect to the project created in GCP and tHe agent created in Dialogflow we will have to follow a series of steps starting from authentication\n",
    "### Authentication\n",
    "Authentication as a service account in the Google Cloud Platform to access the resources in the cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate the computer as a service account\n",
    "service_account_key = os.getenv('service_account_key')\n",
    "credentials = service_account.Credentials.from_service_account_file(service_account_key)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session Creation\n",
    "A session represents a conversation between a Dialogflow agent and an end-user. You create a session at the beginning of a conversation and use it for each turn of the conversation. Once the conversation has ended, you discontinue using the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = uuid.uuid4().hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the variables to access the databases\n",
    "project_id = os.getenv('project_id')\n",
    "language_code = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the session with the appropriate credentials\n",
    "session_client = dialogflow.SessionsClient(credentials=credentials)\n",
    "\n",
    "session = session_client.session_path(project_id, session_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent function\n",
    "Function that given an input returns the output of by connecting to the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request an answer to our dialogflow agent according to a text\n",
    "def dialogflow_request(text, language_code):\n",
    "    text_input = dialogflow.TextInput(text=text, language_code=language_code)\n",
    "    query_input = dialogflow.QueryInput(text=text_input)\n",
    "    response = session_client.detect_intent(\n",
    "        request={\"session\": session, \"query_input\": query_input}\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Application \n",
    "---\n",
    "Web application using Gradio to interact with the agent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Images\n",
    "The user will hav the opportunity of inputting images to the chatbot. In order to do so the following functions are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get an answer from Dialogflow according to an input\n",
    "def respond(message, chat_history):\n",
    "    # Use the dialogflow function to get the answer\n",
    "    response = dialogflow_request(message, 'en')\n",
    "    bot_message = str(response.query_result.fulfillment_messages[0].text.text[0])\n",
    "    chat_history.append((message, bot_message))\n",
    "    time.sleep(1)\n",
    "    return \"\", chat_history\n",
    "\n",
    "# Function to add text to the chat\n",
    "def add_text(history, text):\n",
    "    history.append((text, None))\n",
    "    return history, respond(text)\n",
    "\n",
    "# Function to add a file\n",
    "def add_file(history, file):\n",
    "    history.append(((file.name,), None))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\borga\\Desktop\\IE Computer Science\\Semester 3\\NLP Conversational Model\\Final Project\\myenv\\lib\\site-packages\\gradio\\components\\chatbot.py:228: UserWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\borga\\Desktop\\IE Computer Science\\Semester 3\\NLP Conversational Model\\Final Project\\myenv\\lib\\site-packages\\gradio\\components\\textbox.py:259: UserWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7887\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7887/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradio Web App\n",
    "with gr.Blocks() as demo:\n",
    "    # Create a chatbot component\n",
    "    chatbot = gr.Chatbot([], elem_id=\"chatbot\", label=\"FitBot\").style()\n",
    "    with gr.Row():\n",
    "        # Create a textbox component\n",
    "        with gr.Column(scale=0.85):\n",
    "            msg = gr.Textbox(\n",
    "                show_label=False,\n",
    "                placeholder=\"Enter text and press enter, or upload an image\",\n",
    "            ).style(container=False)\n",
    "        with gr.Column(scale=0.15, min_width=0):\n",
    "            # Create an upload button component to add images\n",
    "            btn = gr.UploadButton(\"üìÅ\", file_types=[\"image\"])\n",
    "    clear_btn = gr.Button(value=\"üóëÔ∏è  Clear\")\n",
    "    \n",
    "    # Call the functions previously created\n",
    "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "    file_msg = btn.upload(add_file, [chatbot, btn], [chatbot], queue=False)\n",
    "    clear_btn.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "# launch the application\n",
    "demo.launch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.language_models import TextGenerationModel\n",
    "from google.cloud import aiplatform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = os.getenv('region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=project_id, location=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = service_account_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from Model: Nutrients are substances that provide the body with energy and the materials it needs to grow, develop, and repair itself. Nutrients are found in food and beverages.\n",
      "Endpoint URL: aiplatform.googleapis.com:443\n"
     ]
    }
   ],
   "source": [
    "# Test of text model\n",
    "parameters = {\n",
    "    \"temperature\": 0.2,  # Temperature controls the degree of randomness in token selection.\n",
    "    \"max_output_tokens\": 1024,  # Token limit determines the maximum amount of text output.\n",
    "    \"top_p\": 0.8,  # Tokens are selected from most probable to least until the sum of their probabilities equals the top_p value.\n",
    "    \"top_k\": 40,  # A top_k of 1 means the selected token is the most probable among all tokens.\n",
    "}\n",
    "\n",
    "model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "response = model.predict('What are nutrients?', **parameters)\n",
    "print(f\"Response from Model: {response.text}\")\n",
    "##print(f\"Raw Response: {response}\")\n",
    "# Create the Vertex AI client\n",
    "client = aiplatform.gapic.PredictionServiceClient()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
